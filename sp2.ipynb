{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krp_sp as k\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import community\n",
    "# load the log values : , log=True\n",
    "#ms, md, mv = k.loadmodels(flag=\"m2\",  use_krp_names=False)\n",
    "#len(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def report(flag, up=40, lo=10, w=None, cutoff=10, krp=False):\n",
    "    ms, md, mv = k.loadmodels(flag=flag, use_krp_names=False)\n",
    "    if krp:\n",
    "        m=\"m0-krp-30000.model\"\n",
    "        ms, md, mv = add_model(m, ms, md, mv, use_krp_names=False)    \n",
    "    vx = k.agg_voclist(mv, md, w=w)\n",
    "    v2 = k.red_voclist(vx, up=up, lo=lo)\n",
    "    sx = k.vocmatrix(v2, size=len(md), vsize=len(mv[0]), w=w)\n",
    "    res = k.evalvocmatrix(sx, ms, cutoff=cutoff)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_res(ms, md, mv, up=40, lo=10, w=None, cutoff=10):\n",
    "    vx = k.agg_voclist(mv, md, w=w)\n",
    "    v2 = k.red_voclist(vx, up=up, lo=lo)\n",
    "    sx = k.vocmatrix(v2, size=len(md), vsize=len(mv[0]), w=w)\n",
    "    res = k.evalvocmatrix(sx, ms, cutoff=cutoff)\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model(m, ms, md, mv, use_krp_names=True):\n",
    "    mdir = \"model\"\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    vl = k.loadvoc(m)\n",
    "    mv.append(vl)\n",
    "    sp.load(\"%s/%s\" % (mdir, m))\n",
    "    md.append(sp)\n",
    "    if use_krp_names:\n",
    "        ms.append(krp_names[m.split(\"-\")[1]])\n",
    "    else:\n",
    "        ms.append(m.split(\"-\")[1])\n",
    "    return (ms, md, mv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=\"m5\"\n",
    "ms, md, mv = k.loadmodels(flag=flag, use_krp_names=False)\n",
    "vx = k.agg_voclist(mv, md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag=\"m2\"\n",
    "ms, md, mv = k.loadmodels(flag=flag,  use_krp_names=False)\n",
    "m=\"m0-krp-30000.model\"\n",
    "ms, md, mv = add_model(m, ms, md, mv, use_krp_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=[\"m2\", \"m5\", \"m7\", \"m9\"]\n",
    "labels={\"m2\" : \"30000\", \"m5\" : \"20000\", \"m7\" : \"15000\", \"m9\" : \"10000\", \n",
    "        \"None\" : \"Count\", \"score\" : \"Comb.prop\", \"pos\" : \"Position\"}\n",
    "limits=[(70,35), (30, 5), (3,1)]\n",
    "weights=[None, 'score', 'pos']\n",
    "of=codecs.open(\"report1.txt\", \"w\", \"utf-8\")\n",
    "reps=[]\n",
    "cnt=0\n",
    "ct=10\n",
    "for flag in flags:\n",
    "    for up, lo in limits:\n",
    "        for w in weights:\n",
    "            res=report(flag, up, lo, w)\n",
    "            if w is None:\n",
    "                w=\"None\"\n",
    "            flx=(flag, up, lo, w)\n",
    "            #print(flx)\n",
    "            ofh=codecs.open(\"rep/%s-%3.3d-%3.3d-%s.html\" % flx, \"w\", \"utf-8\")\n",
    "            ofh.write(\"\"\"<html><head>\n",
    "  <meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\" />\n",
    "  </head><body><h1>Result for calculation %d</h1>\n",
    "            <p>Parameters: Vocab.size:%s, limits: %d,%d, Combination: %s</p>\n",
    "            <table>\\n\"\"\" % (cnt, labels[flag], up, lo, labels[w]))\n",
    "            ofh.write(\"<tr><th>部類</th><th>Self/Other</th><th>Most related部類</th></tr>\")\n",
    "            reps.append((flx, res))\n",
    "            cnt += 1\n",
    "            if w is None:\n",
    "                info = \"flag:%s,up:%d,lo:%d,score:None\" % (flag, up, lo)\n",
    "            else:\n",
    "                info = \"flag:%s,up:%d,lo:%d,score:%s\" % (flag, up, lo, w)\n",
    "            of.write(\"====\\n%s\\n\\n\" % (info))    \n",
    "            kr=list(res.keys())\n",
    "            kr.sort()\n",
    "            bu=defaultdict(list)\n",
    "            bldict={}\n",
    "            for r in kr:\n",
    "                s = r[0:3]\n",
    "                c = Counter([a[0][0:3] for a in res[r]])\n",
    "                other = sum([a[1] for a in c.items() if a[0] != s])\n",
    "                bu[s].append((c[s], other))\n",
    "                bldict[r] = \"%2.2d / %2.2d\" % (c[s], other)\n",
    "            for r in kr:\n",
    "                # should integrate the following table here!\n",
    "                rvx = evd[r]\n",
    "                rx=[]\n",
    "                for a in res[r]:\n",
    "                    if a[0] in rvx:\n",
    "                        rtmp=\"<b>%s:%s</b>\" % (a[0], k.krp_names[a[0]])\n",
    "                    else:\n",
    "                        rtmp=\"%s:%s\" % (a[0], k.krp_names[a[0]])\n",
    "                    rx.append(rtmp)\n",
    "                #rx=[\"%s:%s\" % (a[0], k.krp_names[a[0]]) for a in res[r]]\n",
    "                #ofh.write(\"%s\\t%s\\t%s\\t%s\\n\" % (r, k.krp_names[r], bldict[r], \",\".join(rx[0:5])))\n",
    "                ofh.write(\"<tr><td>%s %s</td><td>%s</td><td>%s</td></tr>\\n\" % (r, k.krp_names[r], bldict[r], \",\".join(rx[0:ct])))\n",
    "            #of.write(\"\\n==Self/other\\n\")\n",
    "            ofh.write(\"</table></body></html>\")\n",
    "            ofh.close()\n",
    "            of.write(\"\\n==s/o, bu\\n\")\n",
    "            bs=list(bu.keys())\n",
    "            bs.sort()\n",
    "            for b in bs:\n",
    "                of.write(\"%s\\t%d\\t%d\\t%s\\n\" % (b, sum([a[0] for a in bu[b]]), sum([a[1] for a in bu[b]]), info))\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "(largest_hub, degree) = sorted(node_and_degree, key=itemgetter(1))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(largest_hub, degree) = sorted(node_and_degree, key=itemgetter(1))[-1]\n",
    "hub_ego = nx.ego_graph(G, largest_hub)\n",
    "pos = nx.spring_layout(hub_ego)\n",
    "nx.draw(hub_ego, pos, node_color='b', node_size=10, with_labels=True)\n",
    "    # Draw ego as large and red\n",
    "#nx.draw_networkx_nodes(hub_ego, pos, nodelist=[largest_hub], node_size=600, node_color='r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_ego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nx.connected_component_subgraphs(G):\n",
    "    dir(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = k.vocmatrix(v2, size=75, w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dictionary that holds the calculation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bud=defaultdict(lambda: defaultdict(list))\n",
    "#bus=defaultdict(list)\n",
    "for fl, res in reps:\n",
    "    key=\"%s-%3.3d-%3.3d-%s.html\" % fl\n",
    "    #key = \"%d/%d:%s\" % fl[1:]\n",
    "    k1 = fl[0]\n",
    "    rk=list(res.keys())\n",
    "    rk.sort()\n",
    "    bu=defaultdict(list)\n",
    "    for r in rk:\n",
    "        s = r[0:3]\n",
    "        c = Counter([a[0][0:3] for a in res[r]])\n",
    "        other = sum([a[1] for a in c.items()]) - c[s]\n",
    "        bu[s].append((c[s], other))\n",
    "    bs=list(bu.keys())\n",
    "    bs.sort()\n",
    "    for b in bs:\n",
    "        bud[b][k1].append((key, sum([a[0] for a in bu[b]]), \n",
    "                                 sum([a[1] for a in bu[b]])))\n",
    "        #bus[b].append((key, sum([a[0] for a in bu[b]]), sum([a[1] for a in bu[b]])))\n",
    "    \n",
    "    #print (rk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus=[]\n",
    "pd = {1:3,2:5,3:6}\n",
    "vt=\"eval.txt\"\n",
    "evd=defaultdict(list)\n",
    "for line in codecs.open(vt, \"r\", \"utf-8\"):\n",
    "    l=line[:-1].split(\"\\t\")\n",
    "    bl = l[0].split()[0]\n",
    "    for bx in l[1].split(\",\"):\n",
    "        if \":\" in bx:\n",
    "            evd[bl].append(bx.split(\":\")[0])\n",
    "ek = list(evd.keys())\n",
    "ek.sort()\n",
    "for fl, res in reps:\n",
    "    key=\"%s-%3.3d-%3.3d-%s\" % fl\n",
    "    #key = \"%d/%d:%s\" % fl[1:]\n",
    "    k1 = fl[0]\n",
    "    rk=list(evd.keys())\n",
    "    rk.sort()\n",
    "    evsum = 0\n",
    "    for r in rk:\n",
    "        if r in res:\n",
    "            rl = [a[0] for a in res[r][:3]]\n",
    "            for a in rl:\n",
    "                if r in ek:\n",
    "                    if a in evd[r]:\n",
    "                        evsum +=  (10 - rl.index(a))\n",
    "                        #print(key, a, rl.index(a))\n",
    "    bus.append((key, evsum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the calculation results to a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=\"m2\"\n",
    "labels={\"m2\" : \"3万\", \"m5\" : \"2万\", \"m7\" : \"1.5万\", \"m9\" : \"1万\", \n",
    "        \"None\" : \"Count\", \"score\" : \"Comb.prop\", \"pos\" : \"Position\"}\n",
    "ms, md, mv = k.loadmodels(flag=flag,  use_krp_names=False)\n",
    "bcnt= Counter([a[0:3] for a in ms if len(a) == 4])\n",
    "ofh=codecs.open(\"rep/sp-self-other-results.html\", \"w\", \"utf-8\")\n",
    "ofh.write(\"\"\"<html><head>\n",
    "  <meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\" />\n",
    "  </head><body>\"\"\")\n",
    "ofh.write(\"<h1>Sentencepiece calculation results</h1>\")\n",
    "ofh.write(\"<h2>Evaluation against <a href='../eval.txt'>standard</a></h2><table>\")\n",
    "ofh.write(\"<tr><th>VocSize</th><th>Comb.</th><th>上/下</th><th>Score</th><th>Comm.</th></tr>\")\n",
    "st = sorted(bus, key=lambda x : x[1], reverse=True)\n",
    "for s in st:\n",
    "    ss=tuple(map(int, s[0].split('-')[1:3]))\n",
    "    nxx=s[0].split(\"-\")[0]\n",
    "    w=s[0].split(\"-\")[3].split(\".\")[0]\n",
    "    try:\n",
    "        ccnt = com[s[0]][0]\n",
    "    except:\n",
    "        ccnt = 0\n",
    "    ofh.write(\"<tr><td>%s</td><td>%s</td><td>%d/%d</td><td><a href='%s.html'>%d</a></td><td><a href='%s-comm.html'>%d</a></td></tr>\\n\" % (labels[nxx], labels[w], ss[0], ss[1], s[0], s[1], s[0], ccnt))\n",
    "ofh.write(\"</table>\")\n",
    "ofh.write(\"<h2>Self(=same 部) / Other (=other 部) results</h2>\")\n",
    "ofh.write(\"<p>Results for different values of the upper and lower limits (上下) and vocabulary size (3万, 2万).</p>\")\n",
    "ofh.write(\"<p>For all subcategories 部類 in a category 部, for the 10 most similar subcategories, a same/other calculation is performed, the maximal score is thus 10 times the number of the subcategories for a given category.</p>\")\n",
    "th2 = \"<th>3万</th><th>2万</th><th>1.5万</th><th>1万</th>\"\n",
    "bk=list(bud.keys())\n",
    "bk.sort()\n",
    "for bx in bk:\n",
    "    ofh.write(\"<h3>%s %s (%d部類)</h3>\" % (bx, k.krp_names[bx], bcnt[bx]))\n",
    "    flags = list(bud[bx].keys())\n",
    "    flags.sort()\n",
    "    ofh.write(\"<table border='1'><caption>Results for %s</caption>\" % bx )\n",
    "    ofh.write(\"<tr><th>Limit</th><th colspan='4'>Count</th><th colspan='4'>Prob.</th><th colspan='4'>Pos</th></tr>\")\n",
    "    ofh.write(\"<tr><th>上下</th>%s%s%s</tr>\" % (th2, th2, th2))\n",
    "    rp1 = bud[bx][flags[0]]\n",
    "    rp2 = bud[bx][flags[1]]\n",
    "    ofh.write (\"<tr>\")\n",
    "    for i, p in enumerate(rp1):\n",
    "        if (i % 3 == 0):\n",
    "            ss=tuple(map(int, p[0].split('-')[1:3]))\n",
    "            ofh.write(\"</tr><tr><td>%d/%d</td>\" % (ss))\n",
    "        val = (p[1] / sum(p[1:])) * 100\n",
    "        ofh.write (\"<td><a href='%s'>%2.2f</a></td>\\n\" % (p[0], val))\n",
    "        for fx in flags[1:]:\n",
    "            #print( bud[bx][fx][i])\n",
    "            px=bud[bx][fx][i]\n",
    "            val = (px[1] / sum(px[1:])) * 100\n",
    "            ofh.write (\"<td><a href='%s'>%2.2f</a></td>\\n\" % (px[0], val))\n",
    "    ofh.write (\"</tr>\")\n",
    "    ofh.write(\"</table>\")\n",
    "ofh.write(\"</body></html>\")\n",
    "ofh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bud[bx].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network, community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=reps[4][1]\n",
    "o=[]\n",
    "G = nx.Graph()\n",
    "for r in res:\n",
    "    for s in res[r]:\n",
    "        o.append((r, s[0], s[1]))\n",
    "G.add_weighted_edges_from(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "partition = community.best_partition(G)\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community.best_partition(G)\n",
    "plist = defaultdict(list)\n",
    "[plist[a[1]].append(a[0]) for a in partition.items()]\n",
    "for pl in plist:\n",
    "    pll=plist[pl]\n",
    "    pll.sort()\n",
    "    pll=[\"%s %s\" % (a, k.krp_names[a]) for a in pll]\n",
    "    print (pl, len(pll), \",\".join(pll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in G.nodes:\n",
    "    G.nodes[g]['label']=k.krp_names[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab size histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags=[\"m2\", \"m5\", \"m7\", \"m9\"]\n",
    "cnt=220\n",
    "cut=5\n",
    "width=1\n",
    "for flag in flags:\n",
    "    ms, md, mv = k.loadmodels(flag=flag, use_krp_names=False)\n",
    "    vx = k.agg_voclist(mv, md)\n",
    "    vsize = len(mv[0])\n",
    "    labels, values = zip(*Counter([len(a[1]) for a in vx.items()]).items())\n",
    "    cnt += 1\n",
    "    plt.subplot(cnt)\n",
    "    plt.title(\"SP Histogram, Vocab.Size=%d\" % (vsize))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"No of bulei\")\n",
    "    indexes = np.arange(cut, len(labels))\n",
    "    plt.bar(indexes, values[cut:], width)\n",
    "    \n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.6,\n",
    "                    wspace=0.45)    \n",
    "plt.savefig(\"vsize-hist-%d.png\" % (vsize))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk=list(vx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=1\n",
    "flags=[\"m2\", \"m5\", \"m7\", \"m9\"]\n",
    "cnt = 220\n",
    "for flag in flags:\n",
    "    ms, md, mv = k.loadmodels(flag=flag, use_krp_names=False)\n",
    "    vx = k.agg_voclist(mv, md)\n",
    "    vsize = len(mv[0])\n",
    "    cut=0\n",
    "    labels, values = zip(*Counter([len(a[0]) for a in vx.items()]).items())\n",
    "    cnt += 1\n",
    "    plt.subplot(cnt)\n",
    "    plt.title(\"SP Voc.length vsize=%d\" % (vsize))\n",
    "    plt.ylabel(\"No of items\")\n",
    "    plt.xlabel(\"Length\")\n",
    "    indexes = np.arange(cut, len(labels))\n",
    "    plt.bar(indexes, values[cut:], width)\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.6,\n",
    "                    wspace=0.45)    \n",
    "plt.savefig(\"vlength-hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=reps[6][1]\n",
    "com=defaultdict(list)\n",
    "for resx in reps:\n",
    "    res=resx[1]\n",
    "    name=\"%s-%3.3d-%3.3d-%s\" % resx[0]\n",
    "    #res=reps[6][1]\n",
    "    o=[]\n",
    "    G = nx.Graph()\n",
    "    for r in res:\n",
    "        for s in res[r]:\n",
    "            o.append((r, s[0], s[1]))\n",
    "    G.add_weighted_edges_from(o)\n",
    "    for g in G.nodes:\n",
    "        G.nodes[g]['label']=k.krp_names[g]\n",
    "    G.graph[\"name\"] = name\n",
    "    nx.write_gexf(G, \"rep/%s-%3.3d-%3.3d-%s.gexf\" % resx[0])\n",
    "    partition = community.best_partition(G)\n",
    "    size = float(len(set(partition.values())))\n",
    "    plist = defaultdict(list)\n",
    "    [plist[a[1]].append(a[0]) for a in partition.items()]\n",
    "    com[name].append(len(plist))\n",
    "    ofh=codecs.open(\"rep/%s-%3.3d-%3.3d-%s-comm.html\" % resx[0], \"w\", \"utf-8\")\n",
    "    ofh.write(\"\"\"<html><head>\n",
    "  <meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\" />\n",
    "  </head><body>\"\"\")\n",
    "    ofh.write(\"# Parameters: %s %d/%d %s\\n\" % (resx[0]))\n",
    "    ofh.write(\"# Communities: %d\\n\" % (len(plist)))\n",
    "    ofh.write(\"<table><tr><th>No</th><th>Size</th><th>Members</th></tr>\")\n",
    "    for pl in plist:\n",
    "        pll=plist[pl]\n",
    "        pll.sort()\n",
    "        pll=[\"%s %s\" % (a, k.krp_names[a]) for a in pll]\n",
    "        ofh.write(\"<tr><td>%d</td><td>%d</td><td>%s</td></tr>\\n\" % (pl, len(pll), \",\".join(pll)))\n",
    "    ofh.write(\"</table></body></html>\\n\")\n",
    "    ofh.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "partition = community.best_partition(G)\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community.best_partition(G)\n",
    "plist = defaultdict(list)\n",
    "[plist[a[1]].append(a[0]) for a in partition.items()]\n",
    "for pl in plist:\n",
    "    pll=plist[pl]\n",
    "    pll.sort()\n",
    "    pll=[\"%s %s\" % (a, k.krp_names[a]) for a in pll]\n",
    "    print (pl, len(pll), \",\".join(pll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"ntest.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple((\"a\", resx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
